[
  {
    "objectID": "robot-summer.html",
    "href": "robot-summer.html",
    "title": "Robot",
    "section": "",
    "text": "Robot Summer Project - Summer 2022\n\n\nTwo DC brushless motors hooked up to an Arduino Nano through an H-Bridge PCB, controlled using two independant PWM pins and a hand-tuned PID controller based on the location of the tape relative to the center of the front of the robot."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Some of my interests outside of academics include playing the guitar, scuba diving, and running.\n\n\n\n\nMe and some friends in our gear post-advanced open water certification\n\nI ran a marathon in October 2024, in the middle of the school semester. It was a huge challenge to train during the school semester, but it ended up being immensely rewarding to finish the full marathon. I will be running again to beat my time!\n\n\n\n\nMe running in the 2024 Toronto Waterfront Marathon. Can’t you tell how happy I am?"
  },
  {
    "objectID": "machine-learning.html",
    "href": "machine-learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "This was a machine learning course that focused on an end-of-term competition, where teams of two developed machine learning models for self-driving and character recognition and competed in a simulated competition.\n\n\n\n\n\nCompetition environment. Bottom left is POV from car\n\nA large challenge in this project was collecting data for the models. The driving model required creative ways to collect meaningful data, and the character recognition required a more traditional data augmentation approach.\n\n\nAs the driving controller utilized imitation learning, the model required “expert trajectories”, which is essentially a labelled dataset that is comprised of a given model input to a given model output. In this case, the labelled data was a given POV of the car (visual input) and the output was the driving command that was issued at that time, which was assumed to be the optimal controller choice, something my driving instructor would disagree with.\nThe key issue with collecting data is that when the model is nearly finished training with the dataset, and you need to collect a bit more data to ‘nudge’ the controller in the desired direction, there is already so much data that a few more does not make a large impact.\nThis was inspiration for my own custom method: SAIL (Selective Aggregation for Imitation Learning). This is the contribution for which I am most proud to this project. There is an existing method called DAgger (for example, in this paper on drone control), in which humans add, or aggregate to a dataset based on observed performance, to adjust the behavior of a model.\nThe main issue I found is that the new data is always littered with redundant data, or data that already agrees with the current behaviour. Thus by adding 50% redundant data and 50% new data, the effect of the new data is limited.\nThe solution that I came up with for this is by taking each new datapoint, running it through the current controller, and only adding it to the dataset if the outputs disagree with each other. This way, we include new expert labelled data without diluting the dataset with redundant data that the model already knows.\nI am very proud of coming up with this method, as I have not seen it in the literature.\n\n\n\n\nVarious debugging tools used while training the models, and the computer vision methods to pre-process, including binary masking on a certain RGB range, filtering, and polygon detection.The pre-processing was done in OpenCV and later fed into a custom CNN\n\n\n\n\nThe data collection for the image recognition model was much simpler. By finding the font that matched the existing license plates in simulation, I was able to augment the data using OpenCV to both replicate the existing perspective warps and angles that may exist in the simulation, and at the same time make the model more robust by training it on characters that were further distorted than what it will be given in-sim.\n\n\n\n\nOutput of character recognition model on custom-made pre-processed data.\n\nThis work demonstrates key steps in image preprocessing, such as binary masking, data augmentation, and the creation of a labeled dataset, along with the use of CNNs for character recognition. I was extremely proud of this work and thoroughly enjoyed it from start to finish."
  },
  {
    "objectID": "machine-learning.html#enph-353-project-self-driving-and-character-recognition",
    "href": "machine-learning.html#enph-353-project-self-driving-and-character-recognition",
    "title": "Machine Learning",
    "section": "",
    "text": "This was a machine learning course that focused on an end-of-term competition, where teams of two developed machine learning models for self-driving and character recognition and competed in a simulated competition.\n\n\n\n\n\nCompetition environment. Bottom left is POV from car\n\nA large challenge in this project was collecting data for the models. The driving model required creative ways to collect meaningful data, and the character recognition required a more traditional data augmentation approach.\n\n\nAs the driving controller utilized imitation learning, the model required “expert trajectories”, which is essentially a labelled dataset that is comprised of a given model input to a given model output. In this case, the labelled data was a given POV of the car (visual input) and the output was the driving command that was issued at that time, which was assumed to be the optimal controller choice, something my driving instructor would disagree with.\nThe key issue with collecting data is that when the model is nearly finished training with the dataset, and you need to collect a bit more data to ‘nudge’ the controller in the desired direction, there is already so much data that a few more does not make a large impact.\nThis was inspiration for my own custom method: SAIL (Selective Aggregation for Imitation Learning). This is the contribution for which I am most proud to this project. There is an existing method called DAgger (for example, in this paper on drone control), in which humans add, or aggregate to a dataset based on observed performance, to adjust the behavior of a model.\nThe main issue I found is that the new data is always littered with redundant data, or data that already agrees with the current behaviour. Thus by adding 50% redundant data and 50% new data, the effect of the new data is limited.\nThe solution that I came up with for this is by taking each new datapoint, running it through the current controller, and only adding it to the dataset if the outputs disagree with each other. This way, we include new expert labelled data without diluting the dataset with redundant data that the model already knows.\nI am very proud of coming up with this method, as I have not seen it in the literature.\n\n\n\n\nVarious debugging tools used while training the models, and the computer vision methods to pre-process, including binary masking on a certain RGB range, filtering, and polygon detection.The pre-processing was done in OpenCV and later fed into a custom CNN\n\n\n\n\nThe data collection for the image recognition model was much simpler. By finding the font that matched the existing license plates in simulation, I was able to augment the data using OpenCV to both replicate the existing perspective warps and angles that may exist in the simulation, and at the same time make the model more robust by training it on characters that were further distorted than what it will be given in-sim.\n\n\n\n\nOutput of character recognition model on custom-made pre-processed data.\n\nThis work demonstrates key steps in image preprocessing, such as binary masking, data augmentation, and the creation of a labeled dataset, along with the use of CNNs for character recognition. I was extremely proud of this work and thoroughly enjoyed it from start to finish."
  },
  {
    "objectID": "fsae.html",
    "href": "fsae.html",
    "title": "UBC Formula Electric",
    "section": "",
    "text": "Quad-motor torque vectoring algorithm\nSept. 2024 - Dec. 2025\nThis project aimed to overhaul the team’s driving algorithm, enhancing the car’s performance in driving events at the FSAE Formula Electric competition. The goal was to integrate cutting-edge research on electric motor vehicles and apply control theory to optimize power delivery for maximum efficiency across various driving scenarios.\nThe project was divided into three key modules:\n\nPower Limiting\nSoftware Active Differential\nTraction Control\n\n\n\nTorque Vectoring Drive Algorithm\n2023 - 2024\n\nThe goal of this project was to completely revamp the team’s driving algorithm and to improve the car’s performance in driving events at the FSAE Formula Electric competition. We went into this project looking to utilize the most recent research being done on electric motor vehicles, and apply our knowledge of control theory to create an algorithm that utilized all the available power the vehicle could deliver in the most efficient way possible for all the different driving events.\nThe project was split into three main modules:\n\nPower limiting\nSoftware active differential\nTraction Control\n\n\n1. Power Limiting Module\nThe goal of this module was to calculate the absolute most available power to the car at any given point, while taking in safety considerations including the temperature limits of our motors and inverters, the state of charge of our battery pack, and of course the driver’s inputs, e.g. steering wheel angle and accelerator/brake pedal positions. The limiting factor for power limit is often the battery’s state of charge (SOC). We cannot use regenerative braking too much at high SOC, and we can’t pull too much power from the battery at low SOC, due to voltage sagging under high discharge currents.\n\n\n2. Software Active Differential\nThis module takes in the steering wheel angle as input, and modulates the left-to-right motor torques to improve the cornering behavior of the car. By applying different torques to each side, we can apply a net moment on the car, causing an angular acceleration in the yaw axis to help us steer around the corner. Additionally, we can take advantage of the traction benefits of the car rolling and causing an increased downforce on the outside wheels of the car.\n\n\nFrom Draou 2013, we substitute wheel speeds \\(\\omega_{L,R}\\) for torque requests \\(T_{L,R}\\)\n\n\n3. Traction Control\nThis module’s job is to detect when we are slipping and reallocate torques to maximize traction with the ground to stabilize the car. You can think of it as a PID loop that is trying to set the slip ratio of the rear wheels with a value near zero."
  },
  {
    "objectID": "os.html",
    "href": "os.html",
    "title": "Operating Systems",
    "section": "",
    "text": "Sept. 2024 - Dec. 2024\nI took the CPEN 331 (Operating Systems) course at UBC, in which I wrote OS-level code to build the foundational components of an operating system, using the educational OS/161 from Harvard’s CS161 course. The main components were synchronization primitive types for multi-threaded programming, a custom-architected filetable system, which manages the synchronized access to files between processes, a custom process management architecture that allows calls of fork(), execv(), and waitpid(), allowing duplicated processes, new process creation, and child process management, and finally, a custom virtual memory system with RAM management, page eviction, and swap space."
  },
  {
    "objectID": "os.html#synchronization",
    "href": "os.html#synchronization",
    "title": "Operating Systems",
    "section": "Synchronization",
    "text": "Synchronization\nI used synchronization primitives (namely spinlocks) to implement higher-level primitives to aid in writing concurrent multi-threaded code for a multi-core machine, including higher-level locks, semaphores, and condition variables.\nThe spinlock uses low-level atomic assembly instruction tas, test-and-set, which allows no interleaving of instructions in other processes. Then, the higher-level primitives like locks and semaphores are built upon the spinlock /inkmplementation to allow more abstract use of synchronization.\nThese synchronization tools were then tested using unit tests that spawned hundreds of threads, and manipulated shared data safely."
  },
  {
    "objectID": "os.html#syscalls---file-management",
    "href": "os.html#syscalls---file-management",
    "title": "Operating Systems",
    "section": "Syscalls - File Management",
    "text": "Syscalls - File Management\nI implemented the syscalls that linux uses to modify files: open(), close(), read(), write(), and lseek(). These syscalls required the implementation of a system-wide data structure that tracks open and closed files, and manages the shared access to them between processes. We followed the standard Unix file system structure with a few small modifications.\n\nStandard Unix file table\n Our version of the Unix file table, using extra data structures to support dup() features elegantly"
  },
  {
    "objectID": "os.html#syscalls---process-creation",
    "href": "os.html#syscalls---process-creation",
    "title": "Operating Systems",
    "section": "Syscalls - process creation",
    "text": "Syscalls - process creation\nI implemented the syscalls fork() and execv(), which are used to create new processes in the kernel.\n\nfork(): Spawn an identical copy of the current running process\nRequired the current process’ address space (the sections of memory that it, alone, has access to) to be copied to the new process in a way that left no duplicate pointers. The way we did this was by copying all of the contents of the parent process’ physical pages onto a set of newly allocated physical pages, and adjusting the address space’ pointers such that any translated virtual addresses in the new (child) process would point to these newly allocated copies\n\n\nexecv(): Replace the current running program with a new one.\nIt required a careful management of kernel memory, while being able to copy up to 64KB of memory from the old address space to the new. We decided on a chunking strategy, where we allocate space on the new user stack, and copy a single kilobyte of memory over at a time. This strategy allows the kernel to stay lean, and reduce the amount of pages required by the kernel on a standard machine, which is a large benefit in real-world kernel design.\n\nImage: Midway through copying arguments from old address space, to new address space, using the kernel stack as a buffer for chunks of strings"
  },
  {
    "objectID": "os.html#virtual-memory-system",
    "href": "os.html#virtual-memory-system",
    "title": "Operating Systems",
    "section": "Virtual memory system",
    "text": "Virtual memory system\n\n\n\nFor the final assignment of this computer engineering course, I designed and implemented a virtual memory system for OS161 to replace the existing DUMBVM, which had no page-tracking and page eviction program. The project involved several key tasks, including servicing TLB faults, implementing paging to enable memory swapping between RAM and disk, and developing a page eviction algorithm, along with implementing swap-space to allow the virtualization of memory, letting the computer allocate more memory than exists in RAM at one time.\nI also added support for the sbrk() system call, enabling dynamic heap memory allocation, and implemented functionality to properly handle memory management during process forking. Additionally, I incorporated a more robust TLB eviction strategy to prevent kernel crashes due to TLB overflow. By replacing DUMBVM with a more comprehensive system, I allowed OS161 to manage multiple processes efficiently, and evict old processes’ memory, providing each with the virtualization of an expansive virtual memory space, even with limited physical (RAM) memory. This project required integration with the MIPS architecture, memory management units, and synchronization protocols, all of which were critical for debugging the system and ensuring proper operation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kyle Mackenzie’s Personal Site",
    "section": "",
    "text": "Welcome\nI’m Kyle Mackenzie, a fifth-year Engineering Physics student at the University of British Columbia.\n\n\n\n\nGithub | LinkedIn | Resume\n\n\n\n\n\n\nAcademics\nI am currently working with Sasha Fedorova out of the Computer and Software Systems research group at UBC, on a memory pre-fetching algorithm using novel machine-learning techniques.\nMy course work includes a mix mix of multi-disciplinary engineering topics, with a focus on high-level mathematics and physics. I have supplemented my studies with a specialization in software and computer systems by choosing technical elective courses in computer engineering.\n\n\nProjects\nI have a mix of experience with projects including working on torque controls for UBC Formula Electric, developing the OS161 operating system, and my Capstone project. Check them out on the other tabs of this website!"
  },
  {
    "objectID": "learning-to-balance.html",
    "href": "learning-to-balance.html",
    "title": "Self-Balancing Robot",
    "section": "",
    "text": "Jan. 2024 - Present\nThis prototype is a part of a team Capstone project, in which we are surveying different controls strategies for robots with unstable dynamics. We are mainly comparing the performance of traditional controls methods including using PID controllers, using a Linear-Quadratic Regulator, and using a Model-Predictive Controller, with the performance of neural-network-based controllers, mainly using Reinforcement Learning.\n\n\nOne of the main challenges of this project is characterizing the dynamics of our robot. The video depicts a prototype, but our main robot has a motor in each of the three axes. This brings about highly complex dynamics equations due to phenomona such as gyroscopic procession, and the conservation of angular momentum.\nI personally worked on the CAD design of the robot. I created a CAD design that could be 3D printed that had the following benefits from the original:\n\nreduced number of parts, easing assembly\nreduced number of fasteners required\nimpact loads taken by 3D printed parts, allowing for smaller, lighter fasteners to be used, reducing total mass.\n\n\n\n\n\nThe gains for the LQR controller are calculated using an optimization algorithm, which takes a sort of cost function as its input. Therefore, the controller is only good as your cost function is, as for any given cost function, the LQR optimization will create an optimal controller to minimize the given function.\nIn our case, our cost function mostly uses the angles of the robot, measured from upright, so that the optimized controller tries to minimize the angle of the robot, keeping it balanced. Additionally, the physics of electric motors create some challenges: All electric motors have a maximum speed, at which torque cannot be further applied in the direction of rotation. Therefore, we need to penalize high motor speeds to make sure the controller never gets itself to a point where it can no longer apply a torque, otherwise it may be unable to self-right. This is a tricky problem that goes beyond classical control theory (at least, at the level we are taught in undergraduate engineering)."
  },
  {
    "objectID": "learning-to-balance.html#what-makes-this-problem-interesting",
    "href": "learning-to-balance.html#what-makes-this-problem-interesting",
    "title": "Self-Balancing Robot",
    "section": "",
    "text": "One of the main challenges of this project is characterizing the dynamics of our robot. The video depicts a prototype, but our main robot has a motor in each of the three axes. This brings about highly complex dynamics equations due to phenomona such as gyroscopic procession, and the conservation of angular momentum.\nI personally worked on the CAD design of the robot. I created a CAD design that could be 3D printed that had the following benefits from the original:\n\nreduced number of parts, easing assembly\nreduced number of fasteners required\nimpact loads taken by 3D printed parts, allowing for smaller, lighter fasteners to be used, reducing total mass."
  },
  {
    "objectID": "learning-to-balance.html#lqr-and-mpc-controller-development",
    "href": "learning-to-balance.html#lqr-and-mpc-controller-development",
    "title": "Self-Balancing Robot",
    "section": "",
    "text": "The gains for the LQR controller are calculated using an optimization algorithm, which takes a sort of cost function as its input. Therefore, the controller is only good as your cost function is, as for any given cost function, the LQR optimization will create an optimal controller to minimize the given function.\nIn our case, our cost function mostly uses the angles of the robot, measured from upright, so that the optimized controller tries to minimize the angle of the robot, keeping it balanced. Additionally, the physics of electric motors create some challenges: All electric motors have a maximum speed, at which torque cannot be further applied in the direction of rotation. Therefore, we need to penalize high motor speeds to make sure the controller never gets itself to a point where it can no longer apply a torque, otherwise it may be unable to self-right. This is a tricky problem that goes beyond classical control theory (at least, at the level we are taught in undergraduate engineering)."
  }
]